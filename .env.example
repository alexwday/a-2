# Environment Configuration Example
# Copy this file to .env and fill in your values

# Base URL for LLM API
# For OpenAI: https://api.openai.com/v1
# For internal: https://your-internal-endpoint.com/v1
BASE_URL=https://api.openai.com/v1

# Authentication Method
# Set to 'false' for API key, 'true' for OAuth
USE_OAUTH=false

# API Key (used when USE_OAUTH=false)
# Get from: https://platform.openai.com/api-keys
API_KEY=sk-...your-api-key-here...

# OAuth Settings (used when USE_OAUTH=true)
OAUTH_URL=https://your-oauth-server.com/oauth2/token
CLIENT_ID=your-client-id
CLIENT_SECRET=your-client-secret

# SSL Settings
# Set to 'true' if using custom CA bundle (typically for internal endpoints)
USE_SSL=false
CA_BUNDLE_PATH=./certs/rbc-ca-bundle.cer

# Model Settings
MODEL=gpt-4.1-2025-04-14
TEMPERATURE=0.7
MAX_TOKENS=2000

# ===== Configuration Examples =====

# LOCAL DEVELOPMENT (OpenAI):
# BASE_URL=https://api.openai.com/v1
# USE_OAUTH=false
# API_KEY=sk-...your-api-key...
# USE_SSL=false

# WORK ENVIRONMENT (Internal):
# BASE_URL=https://internal-llm.company.com/v1
# USE_OAUTH=true
# OAUTH_URL=https://auth.company.com/oauth2/token
# CLIENT_ID=abc123
# CLIENT_SECRET=xyz789
# USE_SSL=true
# CA_BUNDLE_PATH=./certs/rbc-ca-bundle.cer